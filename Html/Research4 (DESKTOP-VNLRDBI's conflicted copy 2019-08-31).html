<html>
<head>
<title>Shaodi YOU - Publications</title>
<meta http-equiv="Content-Type" content="text/html; charset=Helvetica">

<style type="text/css">
p {
	font-family: Arial, Helvetica, sans-serif;
	font-size: 16px;
}
.STYLE3 {font-size: 24px}
</style>
</head>
<body bgcolor="#FFFFFF" leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">
<!-- Save for Web Slices (Untitled-1.psd) -->
<table width="840" height="768" border="0" align="center" cellpadding="0" cellspacing="0" id="Table_01">
	<tr>
		<td colspan="6">
			<img src="../images/index_01.gif" width="840" height="195" alt=""></td>
	</tr>
	<tr>
		<td rowspan="4" width="20" background="../images/index_02.gif">&nbsp;</td>
		<td width="175" height="53" style="table-layout:fixed>
			<a href="index.html"><a href="../index.html"><img src="../images/HomeGray.gif" alt="" width="175" height="53" border="0"></a></a></td>
		<td rowspan="4" width="65" background="../images/index_12.gif">&nbsp;</td>
		<td width="520" rowspan="4" valign="top"><p class="STYLE3">3D geometry </p>
		  <p class="STYLE3">&nbsp;</p>
		  <p><span class="STYLE3"> Multi-view Rectification of Folded Documents </span></p>
		  <p>IEEE TPAMI, Accepted,  DOI: 10.1109/TPAMI.2017.2675980. 2017. </p>
		  <p><strong>Shaodi You</strong>, <a href="http://research.microsoft.com/en-us/people/yasumat/" target="_blank">Yasuyuki Matsushita</a>, <a href="http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CB4QFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fjump%2F75451&ei=6sgGVa_zJobm8AXd-4CwDw&usg=AFQjCNE0wuiLZ7bvwl4BgzxNAyqDOyX1FQ&sig2=H-a-i_Sw3Vh-croB_8CWig" target="_blank">Sudipta Sinha</a>, Yusuke Bou and <a href="http://www.cvl.iis.u-tokyo.ac.jp/~ki/">Katsushi Ikeuchi</a></p>
		  <p><img src="../PubImage/Origami.png" alt="Origami" width="520" height="270"></p>
		  <p align="justify">Digitally unwrapping paper sheets is a crucial step for document scanning and accurate text recognition. This paper presents a method for automatically rectifying curved or folded paper sheets from a small number of images captured from different viewpoints. Unlike previous techniques that require either an expensive 3D scanner or over-simplified parametric representation of the deformations, our method only uses a few images and is based on general developable surface model that can represent diverse sets of deformation of paper sheets. By exploiting the geometric property of developable surfaces, we develop a robust rectification method based on ridge-aware 3D reconstruction of the paper sheet and L1 conformal mapping. We evaluate the proposed technique quantitatively and qualitatively using a wide variety of input documents, such as receipts, book pages and letters. </p>
		  <p><a href="../Downloads/ShaodiYou_Origami.pdf">Paper</a> (3.0MB)<br>
		    <a href="../Origami2017/Shaodi_Origami2017.html" target="_blank">Webpage</a></p>
		  <p class="STYLE3">&nbsp;</p>
		  <p class="STYLE3">&nbsp;</p>
		  <p class="STYLE3">Waterdrop Stereo </p>
		  <p><strong>Shaodi You</strong>, <a href="http://php-robbytan.rhcloud.com/">Robby T. Tan</a>, <a href="http://www.cvl.iis.u-tokyo.ac.jp/~rei/">Rei Kawakami</a>, <a href="http://omilab.naist.jp/~mukaigawa/" target="_blank">Yasuhiro Mukaigawa</a> and <a href="http://www.cvl.iis.u-tokyo.ac.jp/~ki/">Katsushi Ikeuchi</a></p>
		  <p><img src="../PubImage/Stereo.png" alt="Stereo" width="520" height="137"></p>
		  <p>This paper introduces depth estimation from water drops. The key idea is that a single water drop adhered to window glass is totally transparent and convex, and thus optically acts like a fisheye lens. If we have more than one water drop in a single image, then through each of them we can see the environment with different view points, similar to  stereo. To realize this idea, we need to rectify every water drop imagery to make radially distorted planar surfaces look flat. For this rectification, we consider two physical properties of water drops: (1)  A static water drop has constant volume, and its geometric convex shape is determined by the balance between the tension force and gravity. This implies that the 3D geometric shape can be obtained by minimizing  the overall potential energy, which is the sum of the tension energy and the gravitational potential energy. (2) The imagery inside a water-drop is determined by the water-drop 3D shape and total reflection at the boundary. This total reflection generates a dark band commonly observed in any adherent water drops. Hence, once the 3D shape of water drops are recovered, we can rectify the water drop images through backward raytracing. Subsequently, we can compute depth using stereo. In addition to depth estimation, we can also apply image refocusing. Experiments on real images and a quantitative evaluation show the effectiveness of our proposed method. To our best knowledge, never before have adherent water drops been used to estimate depth.</p>
		  <p><a href="../Downloads/ShaodiYOU_Stereo.pdf" target="_blank">pdf</a> (3.5MB)</p>
		  <p class="STYLE3">&nbsp;</p>
		  <p class="STYLE3">&nbsp;</p>
		  <p align="justify" class="STYLE3">Thing Locally, Fit Globally: 
		    Robust and Fast 3D Shape Matching 
		    via Adaptive Algebraic Fitting</p>
		  <p align="justify">Appeared in  NeuralComputing,  DOI 10.1016/j.neucom.2016.06.086 </p>
		  <p align="justify"><strong>Shaodi You </strong></p>
		  <p align="justify" class="STYLE3"><img src="../PubImage/R1.jpg" alt="Algebraic" width="520" height="321"></p>
		  <p align="justify">We propose a novel 3D free form surface matching method based 
		    on a novel key-point detector and a novel feature descriptor. The proposed
		    detector is based on algebraic surface fitting. By global smooth fitting, our detector
		    achieved high computational efficiency and robustness against non-rigid
		    deformations. For the feature descriptor, we provide algorithms to compute
		    3D critical net which generates a meaningful structure on standalone local keypoints. 
		    The scale invariant and deformation robust Dual Spin Image descriptor 
		    is provided based on the 3D critical net. Our method is proved by solid 
		    mathematics. Intensive quantitative experiments demonstrate the robustness, 
		    efficiency and accuracy of the proposed method.</p>
		  <p align="justify"><a href="../Downloads/ShaodiYOU_NeuralComp.pdf">Paper</a></p>
		  <p class="STYLE3">&nbsp;</p>
		  <p class="STYLE3">&nbsp;</p>
		  <p><span class="STYLE3">Manifold    Topological Multi-Resolution Analysis Method</span></p>
		  <p>Appeared in  <a href="http://www.journals.elsevier.com/pattern-recognition/">Pattern Recognition</a></p>
<p><strong>Shaodi You</strong> and <a href="http://oa.ee.tsinghua.edu.cn/~mahuimin/index.htm">Huimin Ma</a> </p>
<p><img src="../PubImage/Pub2.jpg" width="520" height="303"></p>
<p align="justify">In this paper, two significant weaknesses of locally linear embedding (LLE) applied to computer vision 
  are addressed: &quot;intrinsic dimension&quot; and &quot;eigenvector meanings&quot;. &quot;Topological embedding&quot; and 
  &quot;multi-resolution nonlinearity capture&quot; are introduced based on mathematical analysis of topological 
  manifolds and LLE. The manifold topological analysis (MTA) method is described and is based on 
  &quot;topological embedding&quot;. MTA is a more robust method to determine the &quot;intrinsic dimension&quot; of a 
  manifold with typical topology, which is important for tracking and perception understanding. The 
  manifold multi-resolution analysis (MMA) method is based on &quot;multi-resolution nonlinearity capture&quot;. 
  MMA defines LLE eigenvectors as features for pattern recognition and dimension reduction. Both MTA 
  and MMA are proved mathematically, and several examples are provided. Applications in 3D object 
  recognition and 3D object viewpoint space partitioning are also described.</p>
<p><a href="../Downloads/ShaodiYOU-PR.pdf">Paper</a> (3.8MB)</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p class="STYLE3">A solution for efficient viewpoint space  partition in 3D object recognition</p>
<p>Oral presentation in ICIG2009</p>
<p> Xiao Yu, <a href="http://oa.ee.tsinghua.edu.cn/~mahuimin/index.htm">Huimin Ma</a>, <strong>Shaodi You</strong> and Ze Yuan</p>
<p><img src="../PubImage/Pub3.jpg" width="520" height="309"></p>
<p align="justify">Viewpoint Space Partition based on Aspect Graph is one of the core techniques of 3D object recognition. Projection images obtained from critical viewpoint following this approach can efficiently provide topological information of an object. Computational complexity has been a huge challenge for obtaining the representation viewpoints used in 3D recognition. In this paper, we discuss inefficiency of calculation due to redundant nonexistent visual events; propose a systematic criterion for edge selection involved in EEE events. Pruning algorithm based on concave-convex property is demonstrated. We further introduce intersect relation into our pruning algorithm. These two methods not only enable the calculation of EEE events, but also can be implemented before viewpoint calculation, hence realizes view-independent pruning algorithm. Finally, analysis on simple representative models supports the effectiveness of our methods. Further investigations on Princeton Models, including airplane, automobile, etc, show a two orders of magnitude reduction in the number of EEE events on average.</p>
<p><a href="../Downloads/ShaodiYOU-ICIG2009.pdf">Paper</a> (0.5MB)</p>
<p>&nbsp;</p>
<p>&nbsp;</p></td>
		<td rowspan="4">
			<img src="../images/index_06.gif" width="40" height="514" alt=""></td>
		<td rowspan="4" width="20" background="../images/index_07.gif">&nbsp;</td>
	</tr>
	<tr>
		<td width="175" height="53" style="table-layout:fixed>
			<a href="Html/CV.html"><p><a href="CV.html"><img src="../images/CVGray.gif" alt="" width="175" height="53" border="0"></a><a href="Research.html"><img src="../images/ResearchBK.gif" width="175" height="53" border="0"></a></a></p>	    </td>
	</tr>
	<tr>
		<td width="175" height="53">
			<a href="Publication.html"></a><a href="Artworks.html"><img src="../images/ArtGray.gif" alt="Artworks" width="175" height="54" border="0"></a></td>
	</tr>
	<tr>
		<td><p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
		  <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    <p>&nbsp;</p>
	    </td>
	</tr>
	<tr>
		<td colspan="6">
			<img src="../images/index_11.gif" width="840" height="59" alt=""></td>
	</tr>
</table>
<!-- End Save for Web Slices -->
</body>
</html>